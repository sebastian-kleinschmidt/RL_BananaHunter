{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning Project: BananaHunter Notebook\n",
    "\n",
    "---\n",
    "\n",
    "This notebook shows how to use the Unity ML-Agents environment to train an agent to collect yellow bananas simultaneously avoiding blue bananas using Deep Reinforcement Learning.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit *Prequisited and Installation* Section in the [README](https://github.com/sebastian-kleinschmidt/RL_BananaHunter/REAMDME.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from agent import Agent\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"simulation/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train an Agent from Scratch\n",
    "\n",
    "The following cells will reset the environment and initialize and train an agent to collect yellow bananas and avoid blue bananas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "agent = Agent(state_size=len(env_info.vector_observations[0]), action_size=brain.vector_action_space_size, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Learning Algorithm\n",
    "The learning algorithm uses Deep-Q-Learning. For a total of *n_episodes* the agents choses an *action* based on the current *state* and collects the *subsequent state/next_state* and the *reward* as result of his previous chosen action.\n",
    "\n",
    "With the state, action, reward and next_state information, the agent adds these information to the replay buffer using the step function, which is implemented in agent class defined in the agent.py. Each 4 steps (defined in the UPDATE_EVERY variable of the class), the agent starts learning, as long as we have enough data in our replay buffer available. We then uniformly sample from the replay buffer 64 tuples.\n",
    "\n",
    "Using the states of the sampled experiences form the replay buffer, a forward pass using the **target neural network** define in the model.py (see description in Section 4.3) for the *next_state* and the action, which would maximize the reward, is performed. Together with the discount rate gamma and the reward for the transition, we compute t_target. Together with the current predictions Q_expected, we can build up out cost function an optimize the network (element-wise mean squared error of Q_expected and Q_targets).\n",
    "\n",
    "If the mean score for the last 100 episodes is above the goal of 13, the current model is saved. It would also be possible to stop the training here, but for visualize how good the model can perform with the maximum number of episodes (determinde by n_episodes), the training continues after reaching the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=2000, max_t=9999, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    prev_best_score_window = 0\n",
    "    best_score_window = 0\n",
    "    \n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset(train_mode=True)[brain_name].vector_observations[0]\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action.astype(int))[brain_name]\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0]\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            if prev_best_score_window!=best_score_window:\n",
    "                prev_best_score_window=best_score_window\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f} - Better Solution found!'.format(i_episode, best_score_window))\n",
    "            else:\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0 and np.mean(scores_window)>best_score_window:\n",
    "            if best_score_window==0:\n",
    "                print('\\nEnvironment solved the first time in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            best_score_window = np.mean(scores_window)\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.00\n",
      "Episode 200\tAverage Score: 4.87\n",
      "Episode 300\tAverage Score: 8.02\n",
      "Episode 400\tAverage Score: 9.86\n",
      "Episode 500\tAverage Score: 12.72\n",
      "Episode 535\tAverage Score: 13.04\n",
      "Environment solved the first time in 435 episodes!\tAverage Score: 13.04\n",
      "Episode 600\tAverage Score: 13.55 - Better Solution found!\n",
      "Episode 700\tAverage Score: 14.40 - Better Solution found!\n",
      "Episode 800\tAverage Score: 14.95 - Better Solution found!\n",
      "Episode 900\tAverage Score: 16.05 - Better Solution found!\n",
      "Episode 1000\tAverage Score: 16.19 - Better Solution found!\n",
      "Episode 1100\tAverage Score: 14.93\n",
      "Episode 1200\tAverage Score: 15.13\n",
      "Episode 1300\tAverage Score: 15.51\n",
      "Episode 1400\tAverage Score: 15.70\n",
      "Episode 1500\tAverage Score: 16.22 - Better Solution found!\n",
      "Episode 1600\tAverage Score: 16.26 - Better Solution found!\n",
      "Episode 1700\tAverage Score: 17.18 - Better Solution found!\n",
      "Episode 1800\tAverage Score: 15.62\n",
      "Episode 1900\tAverage Score: 15.60\n",
      "Episode 2000\tAverage Score: 15.03\n"
     ]
    }
   ],
   "source": [
    "# Define Hyperparameters\n",
    "n_episodes=2000\n",
    "max_t=99999\n",
    "eps_start=1.0\n",
    "eps_end=0.01\n",
    "eps_decay=0.995\n",
    "\n",
    "# Start training\n",
    "scores = dqn(n_episodes, max_t, eps_start, eps_end, eps_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Definition:**\n",
    "- **n_episodes** - *maximum number of training episodes*<br> According to Section 4.3 *2000* is high enough to archieve the goal of the task but might be to high achieving no significant improvement in the second half after approx episode 600.\n",
    "- **max_t** -  *maximum number of timesteps per episode*\n",
    "With a maximum number of timesteps per episode of 99999, each episode should run until it's end.\n",
    "- **eps_start** - *starting value of epsilon, for epsilon-greedy action selection*\n",
    "Epsilon-greedy starts with a value of 1.0 for selecting random actions at first and concentrate on exploration.\n",
    "- **eps_end** - *minimum value of epsilon*\n",
    "Epsilon-greedy starts with a value of 0.1 for using the trained and model (exploiting) and only little roomf or exploration.\n",
    "- **eps_decay** - *multiplicative factor (per episode) for decreasing epsilon*\n",
    "The decay between both values i 0.995 per episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Architecture\n",
    "The architecture of the model is defined in the model.py file. The network is a three linear-layer network with an input size of 37 (according to the number of states), 64 hidden units in the second layer and an output dimension of 4 of the output layer (according to the number of actions). Rectified Linear Unit (ReLU) are used as activation functions for the first and second layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot of Rewards per Episode\n",
    "Subsequently you can see a plot of the score over the number of episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the printed output during training and visualization of the plot, the network was able to solve the task (average reward (over 100 episodes) of at least +13) after episode 452. From this point on, the model further improved until approx. episode xx. Therefore, a reduction of the hyperparameter *n_episodes* seems to be reasonable to episode 750."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Ideas for Future Work\n",
    "- **More sophisticated network architecture**\n",
    "The used network is a very shallow network. A deeper and more sophisticated network might perform better.\n",
    "- **Implement Double Q-Learning**\n",
    "Traditional Deep Q-Learning as used in this implementation tends to overestimates the action values. A possible extension would therefore to use Double Q-Learning.\n",
    "- **Priorized Experience Replay**\n",
    "The implementation samples experience transistions uniformly from the replay buffer. Important transitions can be sampled with higher probabilities using *Priorized Experience Replay* to learn more effectively.\n",
    "- **Dueling DQN**\n",
    "By replacing the tradition Deep-Q-Network with a dueling architecutre, the values of each state can be assessed without having to learn the effect of each action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Demonstrate Trained Agent\n",
    "Now let's load the best performing model and let us see, how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.act(state)        # select an action\n",
    "    env_info = env.step(action.astype(int))[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Shutdown Environment\n",
    "Last thing to do is to shut down the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
